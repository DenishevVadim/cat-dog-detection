{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "polar-parameter",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T08:58:22.098833Z",
     "iopub.status.busy": "2021-04-25T08:58:22.097218Z",
     "iopub.status.idle": "2021-04-25T08:58:25.291821Z",
     "shell.execute_reply": "2021-04-25T08:58:25.291204Z"
    },
    "papermill": {
     "duration": 3.209954,
     "end_time": "2021-04-25T08:58:25.291978",
     "exception": false,
     "start_time": "2021-04-25T08:58:22.082024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "\n",
    "from torch.nn import Conv2d, functional as F, Linear, MaxPool2d, Module\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "\n",
    "import gc\n",
    "from inspect import getsourcefile\n",
    "from os.path import abspath\n",
    "from os import listdir\n",
    "from json import dumps\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import random\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "satellite-trace",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T08:58:25.317608Z",
     "iopub.status.busy": "2021-04-25T08:58:25.317095Z",
     "iopub.status.idle": "2021-04-25T08:58:32.871323Z",
     "shell.execute_reply": "2021-04-25T08:58:32.869920Z"
    },
    "papermill": {
     "duration": 7.568214,
     "end_time": "2021-04-25T08:58:32.871454",
     "exception": false,
     "start_time": "2021-04-25T08:58:25.303240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datadir = \"../input/cats-dogs/\"\n",
    "datanames = []\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/cats-dogs/'):\n",
    "    for filename in filenames:\n",
    "        temp = filename.split('.')\n",
    "        if temp[1] == \"jpg\":\n",
    "            datanames.append(temp[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "outer-absolute",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T08:58:32.901126Z",
     "iopub.status.busy": "2021-04-25T08:58:32.900546Z",
     "iopub.status.idle": "2021-04-25T08:58:32.904423Z",
     "shell.execute_reply": "2021-04-25T08:58:32.903994Z"
    },
    "papermill": {
     "duration": 0.023068,
     "end_time": "2021-04-25T08:58:32.904524",
     "exception": false,
     "start_time": "2021-04-25T08:58:32.881456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.RandomSizedBBoxSafeCrop(width=299, height=299, erosion_rate=0.1, p=0.25),\n",
    "            A.OneOf([\n",
    "                A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, \n",
    "                                     val_shift_limit=0.2, p=0.9),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2, \n",
    "                                           contrast_limit=0.2, p=0.9),\n",
    "            ],p=0.9),\n",
    "            #A.ToGray(p=0.01),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.Rotate(limit=45, p=1),\n",
    "            A.ChannelShuffle(p=0.25),\n",
    "            A.FancyPCA(),\n",
    "            A.GaussNoise(p=0.25),\n",
    "            A.Blur(blur_limit=4,p=0.25),\n",
    "            A.Cutout(num_holes=8, max_h_size=8, max_w_size=8, fill_value=0, p=0.5),\n",
    "            A.Resize(width=299, height=299, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], \n",
    "        p=1.0, \n",
    "        bbox_params = A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0,\n",
    "            min_visibility=0,\n",
    "            label_fields=['field_id']\n",
    "            )\n",
    "    )\n",
    "def get_test_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(width=299, height=299, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], \n",
    "        p=1.0, \n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0, \n",
    "            min_visibility=0,\n",
    "            label_fields=['field_id']\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coupled-sapphire",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T08:58:32.931631Z",
     "iopub.status.busy": "2021-04-25T08:58:32.930990Z",
     "iopub.status.idle": "2021-04-25T08:58:32.933737Z",
     "shell.execute_reply": "2021-04-25T08:58:32.933274Z"
    },
    "papermill": {
     "duration": 0.019739,
     "end_time": "2021-04-25T08:58:32.933854",
     "exception": false,
     "start_time": "2021-04-25T08:58:32.914115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Custom_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, folder_path, datadir, transforms=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.datadir = datadir\n",
    "        self.data_len = len(self.datadir)\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        single_image_path = self.datadir[index]\n",
    "        img = cv2.imread(self.folder_path+ '/' + single_image_path + \".jpg\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #img = Image.open(self.folder_path+ '/' + single_image_path + \".jpg\").convert('RGB')\n",
    "        target =  np.loadtxt(self.folder_path+ '/' + single_image_path + \".txt\")\n",
    "        if self.transforms is not None:\n",
    "            #img = self.transforms(img)\n",
    "            tr = self.transforms(image=img, bboxes=[target[1:]], field_id=['1, 2, 3, 4'])\n",
    "            img, bbox = tr[\"image\"], tr[\"bboxes\"]\n",
    "        img = img.type(torch.float)/255\n",
    "        bbox = torch.tensor(bbox[0])\n",
    "        return (img, np.int_(target[0])-1, bbox)\n",
    "\n",
    "    def __len__(self):  \n",
    "        return self.data_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hybrid-wiring",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T08:58:32.960116Z",
     "iopub.status.busy": "2021-04-25T08:58:32.959453Z",
     "iopub.status.idle": "2021-04-25T08:58:32.962514Z",
     "shell.execute_reply": "2021-04-25T08:58:32.962058Z"
    },
    "papermill": {
     "duration": 0.018909,
     "end_time": "2021-04-25T08:58:32.962614",
     "exception": false,
     "start_time": "2021-04-25T08:58:32.943705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_split_train_test(datadir, datanames, valid_size = .1, batch_size = 128):\n",
    "    num_train = len(datanames)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    custom_dataset_train = Custom_Dataset(datadir, datanames, transforms=get_train_transforms())\n",
    "    loader_train = torch.utils.data.DataLoader(dataset=custom_dataset_train, batch_size=batch_size,\n",
    "                                                       shuffle=False, sampler=train_sampler)\n",
    "    custom_dataset_test = Custom_Dataset(datadir, datanames, transforms=get_test_transforms())\n",
    "    loader_test = torch.utils.data.DataLoader(dataset=custom_dataset_test, batch_size=batch_size,\n",
    "                                                      shuffle=False, sampler=test_sampler)\n",
    "    return loader_train, loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "smooth-burlington",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T08:58:32.996997Z",
     "iopub.status.busy": "2021-04-25T08:58:32.996267Z",
     "iopub.status.idle": "2021-04-25T08:58:32.999001Z",
     "shell.execute_reply": "2021-04-25T08:58:32.998493Z"
    },
    "papermill": {
     "duration": 0.026743,
     "end_time": "2021-04-25T08:58:32.999098",
     "exception": false,
     "start_time": "2021-04-25T08:58:32.972355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel=3, stride=1, padding = 1, pool = False):  # ch_in, ch_out, kernel, stride, padding, groups\n",
    "        super(conv_block, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, kernel, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "        self.act = nn.SiLU()\n",
    "        self.Maxpool = nn.MaxPool2d(4)\n",
    "        self.pool = pool\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        if self.pool: x = self.Maxpool(x)\n",
    "        return x\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes = 2):\n",
    "        super().__init__()\n",
    "        self.conv1 = conv_block(in_channels, 64)\n",
    "        self.res1 = nn.Sequential(conv_block(64, 64), conv_block(64, 64))\n",
    "        self.conv2 = conv_block(64, 128, pool=True) #128 x 32 x 32\n",
    "        self.res2 = nn.Sequential(conv_block(128, 128), conv_block(128, 128), conv_block(128, 128))\n",
    "        self.conv3 = conv_block(128, 512, pool=True) #256 x 8 x 8\n",
    "        self.res3 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
    "        self.conv4 = conv_block(512, 1024, pool=True) #512 x 2 x 2\n",
    "        self.res4 = nn.Sequential(conv_block(1024, 1024), conv_block(1024, 1024, pool = True))\n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4), #1024 x 1 x 1\n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Dropout(0.2),\n",
    "                                        nn.Linear(1024, 256),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(256, 1))\n",
    "        self.bbox = nn.Sequential(nn.MaxPool2d(4), #1024 x 1 x 1\n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Dropout(0.2),\n",
    "                                        nn.Linear(1024, 512),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(512, 4))\n",
    "\n",
    "\n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv2(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.res3(out) + out\n",
    "        out = self.conv4(out)\n",
    "        out = self.res4(out) + out\n",
    "        cl = F.sigmoid(self.classifier(out))\n",
    "        bb = F.sigmoid(self.bbox(out))\n",
    "        return cl, bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "disabled-stability",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T08:58:33.026716Z",
     "iopub.status.busy": "2021-04-25T08:58:33.026096Z",
     "iopub.status.idle": "2021-04-25T08:58:33.028428Z",
     "shell.execute_reply": "2021-04-25T08:58:33.028926Z"
    },
    "papermill": {
     "duration": 0.019902,
     "end_time": "2021-04-25T08:58:33.029038",
     "exception": false,
     "start_time": "2021-04-25T08:58:33.009136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def IoU(boxA, boxB):\n",
    "    iou = 0\n",
    "    for i in range(boxA.shape[0]):\n",
    "        xA = max(boxA[i,0], boxB[i,0])\n",
    "        yA = max(boxA[i,1], boxB[i,1])\n",
    "        xB = min(boxA[i,2], boxB[i,2])\n",
    "        yB = min(boxA[i,3], boxB[i,3])\n",
    "    \n",
    "        interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    \n",
    "        boxAArea = (boxA[i,2] - boxA[i,0] + 1) * (boxA[i,3] - boxA[i,1] + 1)\n",
    "        boxBArea = (boxB[i,2] - boxB[i,0] + 1) * (boxB[i,3] - boxB[i,1] + 1)\n",
    "    \n",
    "        iou += float(interArea) / float(boxAArea + boxBArea - interArea)\n",
    "        \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brown-beast",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T08:58:33.056004Z",
     "iopub.status.busy": "2021-04-25T08:58:33.055299Z",
     "iopub.status.idle": "2021-04-25T08:58:33.057723Z",
     "shell.execute_reply": "2021-04-25T08:58:33.058236Z"
    },
    "papermill": {
     "duration": 0.019356,
     "end_time": "2021-04-25T08:58:33.058349",
     "exception": false,
     "start_time": "2021-04-25T08:58:33.038993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_metrics(model, optimizer, scheduler, train_dl, epoch):\n",
    "    steps = 0\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for x, y_class, y_bb in train_dl:\n",
    "        batch = y_class.shape[0]\n",
    "        steps += 1\n",
    "        optimizer.zero_grad()\n",
    "        x, y_class, y_bb = x.to(device), y_class.to(device).float(), (y_bb.to(device)/299)\n",
    "        out_class, out_bb = model(x)\n",
    "        loss_class = nn.BCELoss()(out_class, y_class.unsqueeze(1))\n",
    "        loss_bb = F.smooth_l1_loss(out_bb.float(), y_bb.float(), reduction=\"sum\")\n",
    "        loss = loss_class + 5*loss_bb\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += batch\n",
    "        sum_loss += loss.item()\n",
    "        #if epoch<23:\n",
    "        scheduler.step()\n",
    "        #elif epoch >30:\n",
    "            \n",
    "    return steps, total, sum_loss, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "greatest-karma",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T08:58:33.088434Z",
     "iopub.status.busy": "2021-04-25T08:58:33.087860Z",
     "iopub.status.idle": "2021-04-25T08:58:33.090806Z",
     "shell.execute_reply": "2021-04-25T08:58:33.090398Z"
    },
    "papermill": {
     "duration": 0.02225,
     "end_time": "2021-04-25T08:58:33.090907",
     "exception": false,
     "start_time": "2021-04-25T08:58:33.068657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def val_metrics(model, valid_dl):\n",
    "    start_time = time.time()\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0 \n",
    "    Iou_loss_cum = 0\n",
    "    for x, y_class, y_bb in valid_dl:\n",
    "        batch = y_class.shape[0]\n",
    "        x, y_class, y_bb = x.to(device), y_class.to(device).float(), (y_bb.to(device)/299)\n",
    "        out_class, out_bb = model(x)\n",
    "        loss_class = nn.BCELoss()(out_class, y_class.unsqueeze(1))\n",
    "        loss_bb = F.smooth_l1_loss(out_bb.float(), y_bb.float(), reduction=\"sum\")\n",
    "        IoU_loss = IoU(out_bb.cpu().detach().numpy(), y_bb.cpu().detach().numpy())\n",
    "        Iou_loss_cum += IoU_loss\n",
    "        loss = loss_class + 5*loss_bb\n",
    "        correct += (out_class.cpu().detach().numpy().round() == y_class.cpu().detach().numpy().reshape(-1,1)).sum()\n",
    "        sum_loss += loss.item()\n",
    "        total += batch\n",
    "        \n",
    "    val_time = (time.time() - start_time)\n",
    "    model.train()\n",
    "    return sum_loss/total, correct/total, Iou_loss_cum/total, model, val_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sexual-subdivision",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T08:58:33.117833Z",
     "iopub.status.busy": "2021-04-25T08:58:33.117214Z",
     "iopub.status.idle": "2021-04-25T08:58:33.119619Z",
     "shell.execute_reply": "2021-04-25T08:58:33.120120Z"
    },
    "papermill": {
     "duration": 0.019171,
     "end_time": "2021-04-25T08:58:33.120242",
     "exception": false,
     "start_time": "2021-04-25T08:58:33.101071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_model(model, optimizer, scheduler, train_dl, val_dl, epochs=10):\n",
    "    best_loss_val = 1\n",
    "    for epoch in range(epochs):\n",
    "        #if epoch > 50:\n",
    "        steps, total, sum_loss, model = train_metrics(model, optimizer, scheduler, train_dl, epoch)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        sum_loss_val, correct, mIoU, model, val_time = val_metrics(model, val_dl)\n",
    "        if epoch>50 and sum_loss_val<=best_loss_val:\n",
    "            best_loss_val = sum_loss_val\n",
    "            torch.save(model.state_dict(), f'epoch:{epoch}_sum_loss_val:{sum_loss_val}.pt')\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"train_loss %.3f val_loss %.3f val_acc %.3f val_mIoU %.3f val_time %.3f\" % (sum_loss/total, sum_loss_val, correct, mIoU, val_time))\n",
    "    return model, sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "entire-librarian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-25T08:58:33.478319Z",
     "iopub.status.busy": "2021-04-25T08:58:33.477661Z",
     "iopub.status.idle": "2021-04-25T12:54:23.957213Z",
     "shell.execute_reply": "2021-04-25T12:54:23.957921Z"
    },
    "papermill": {
     "duration": 14150.82732,
     "end_time": "2021-04-25T12:54:23.958167",
     "exception": false,
     "start_time": "2021-04-25T08:58:33.130847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.426 val_loss 0.347 val_acc 0.673 val_mIoU 0.702 val_time 9.396\n",
      "train_loss 0.366 val_loss 0.308 val_acc 0.675 val_mIoU 0.715 val_time 5.547\n",
      "train_loss 0.334 val_loss 0.398 val_acc 0.670 val_mIoU 0.689 val_time 5.779\n",
      "train_loss 0.302 val_loss 0.312 val_acc 0.694 val_mIoU 0.723 val_time 5.624\n",
      "train_loss 0.280 val_loss 0.249 val_acc 0.706 val_mIoU 0.750 val_time 5.645\n",
      "train_loss 0.254 val_loss 0.251 val_acc 0.714 val_mIoU 0.750 val_time 5.980\n",
      "train_loss 0.225 val_loss 0.242 val_acc 0.743 val_mIoU 0.754 val_time 5.725\n",
      "train_loss 0.206 val_loss 0.180 val_acc 0.691 val_mIoU 0.785 val_time 5.800\n",
      "train_loss 0.190 val_loss 0.158 val_acc 0.673 val_mIoU 0.800 val_time 6.052\n",
      "train_loss 0.183 val_loss 0.257 val_acc 0.675 val_mIoU 0.754 val_time 5.727\n",
      "train_loss 0.169 val_loss 0.187 val_acc 0.756 val_mIoU 0.778 val_time 5.705\n",
      "train_loss 0.158 val_loss 0.132 val_acc 0.784 val_mIoU 0.822 val_time 5.862\n",
      "train_loss 0.157 val_loss 0.149 val_acc 0.808 val_mIoU 0.798 val_time 5.724\n",
      "train_loss 0.153 val_loss 0.228 val_acc 0.818 val_mIoU 0.744 val_time 5.859\n",
      "train_loss 0.146 val_loss 0.147 val_acc 0.860 val_mIoU 0.789 val_time 5.777\n",
      "train_loss 0.137 val_loss 0.132 val_acc 0.855 val_mIoU 0.809 val_time 6.259\n",
      "train_loss 0.135 val_loss 0.183 val_acc 0.839 val_mIoU 0.776 val_time 6.355\n",
      "train_loss 0.128 val_loss 0.206 val_acc 0.831 val_mIoU 0.755 val_time 5.950\n",
      "train_loss 0.133 val_loss 0.112 val_acc 0.829 val_mIoU 0.825 val_time 5.577\n",
      "train_loss 0.121 val_loss 0.123 val_acc 0.875 val_mIoU 0.808 val_time 5.624\n",
      "train_loss 0.122 val_loss 0.090 val_acc 0.917 val_mIoU 0.840 val_time 5.744\n",
      "train_loss 0.114 val_loss 0.164 val_acc 0.849 val_mIoU 0.786 val_time 5.777\n",
      "train_loss 0.114 val_loss 0.106 val_acc 0.901 val_mIoU 0.820 val_time 5.677\n",
      "train_loss 0.112 val_loss 0.122 val_acc 0.901 val_mIoU 0.817 val_time 5.866\n",
      "train_loss 0.104 val_loss 0.106 val_acc 0.899 val_mIoU 0.828 val_time 5.787\n",
      "train_loss 0.099 val_loss 0.078 val_acc 0.875 val_mIoU 0.856 val_time 6.234\n",
      "train_loss 0.102 val_loss 0.098 val_acc 0.873 val_mIoU 0.832 val_time 6.308\n",
      "train_loss 0.098 val_loss 0.083 val_acc 0.901 val_mIoU 0.849 val_time 6.282\n",
      "train_loss 0.093 val_loss 0.212 val_acc 0.881 val_mIoU 0.762 val_time 5.812\n",
      "train_loss 0.097 val_loss 0.177 val_acc 0.917 val_mIoU 0.771 val_time 5.911\n",
      "train_loss 0.095 val_loss 0.142 val_acc 0.629 val_mIoU 0.846 val_time 5.794\n",
      "train_loss 0.092 val_loss 0.067 val_acc 0.919 val_mIoU 0.863 val_time 6.420\n",
      "train_loss 0.084 val_loss 0.071 val_acc 0.919 val_mIoU 0.866 val_time 5.816\n",
      "train_loss 0.088 val_loss 0.073 val_acc 0.932 val_mIoU 0.854 val_time 5.652\n",
      "train_loss 0.079 val_loss 0.130 val_acc 0.927 val_mIoU 0.793 val_time 5.716\n",
      "train_loss 0.079 val_loss 0.063 val_acc 0.899 val_mIoU 0.872 val_time 5.688\n",
      "train_loss 0.081 val_loss 0.092 val_acc 0.940 val_mIoU 0.835 val_time 6.060\n",
      "train_loss 0.078 val_loss 0.109 val_acc 0.919 val_mIoU 0.821 val_time 5.652\n",
      "train_loss 0.074 val_loss 0.074 val_acc 0.961 val_mIoU 0.849 val_time 5.682\n",
      "train_loss 0.079 val_loss 0.079 val_acc 0.883 val_mIoU 0.858 val_time 5.769\n",
      "train_loss 0.076 val_loss 0.079 val_acc 0.958 val_mIoU 0.847 val_time 5.783\n",
      "train_loss 0.070 val_loss 0.061 val_acc 0.951 val_mIoU 0.861 val_time 6.502\n",
      "train_loss 0.074 val_loss 0.054 val_acc 0.958 val_mIoU 0.869 val_time 5.658\n",
      "train_loss 0.069 val_loss 0.078 val_acc 0.914 val_mIoU 0.849 val_time 5.718\n",
      "train_loss 0.070 val_loss 0.071 val_acc 0.948 val_mIoU 0.848 val_time 5.935\n",
      "train_loss 0.067 val_loss 0.067 val_acc 0.948 val_mIoU 0.856 val_time 5.792\n",
      "train_loss 0.063 val_loss 0.076 val_acc 0.938 val_mIoU 0.857 val_time 6.075\n",
      "train_loss 0.062 val_loss 0.085 val_acc 0.888 val_mIoU 0.852 val_time 5.909\n",
      "train_loss 0.064 val_loss 0.095 val_acc 0.932 val_mIoU 0.829 val_time 5.645\n",
      "train_loss 0.063 val_loss 0.087 val_acc 0.971 val_mIoU 0.840 val_time 6.158\n",
      "train_loss 0.063 val_loss 0.087 val_acc 0.948 val_mIoU 0.838 val_time 6.220\n",
      "train_loss 0.060 val_loss 0.097 val_acc 0.771 val_mIoU 0.856 val_time 6.187\n",
      "train_loss 0.056 val_loss 0.070 val_acc 0.966 val_mIoU 0.857 val_time 5.801\n",
      "train_loss 0.055 val_loss 0.081 val_acc 0.795 val_mIoU 0.875 val_time 6.135\n",
      "train_loss 0.053 val_loss 0.048 val_acc 0.971 val_mIoU 0.879 val_time 6.545\n",
      "train_loss 0.054 val_loss 0.068 val_acc 0.969 val_mIoU 0.861 val_time 6.328\n",
      "train_loss 0.053 val_loss 0.059 val_acc 0.951 val_mIoU 0.864 val_time 5.746\n",
      "train_loss 0.051 val_loss 0.073 val_acc 0.956 val_mIoU 0.844 val_time 6.352\n",
      "train_loss 0.050 val_loss 0.065 val_acc 0.964 val_mIoU 0.852 val_time 5.967\n",
      "train_loss 0.050 val_loss 0.043 val_acc 0.971 val_mIoU 0.886 val_time 6.003\n",
      "train_loss 0.045 val_loss 0.062 val_acc 0.969 val_mIoU 0.855 val_time 5.791\n",
      "train_loss 0.047 val_loss 0.041 val_acc 0.956 val_mIoU 0.893 val_time 6.238\n",
      "train_loss 0.044 val_loss 0.041 val_acc 0.966 val_mIoU 0.888 val_time 6.311\n",
      "train_loss 0.044 val_loss 0.044 val_acc 0.966 val_mIoU 0.884 val_time 5.574\n",
      "train_loss 0.045 val_loss 0.042 val_acc 0.958 val_mIoU 0.893 val_time 5.712\n",
      "train_loss 0.043 val_loss 0.037 val_acc 0.979 val_mIoU 0.892 val_time 6.597\n",
      "train_loss 0.042 val_loss 0.044 val_acc 0.974 val_mIoU 0.882 val_time 5.683\n",
      "train_loss 0.038 val_loss 0.055 val_acc 0.925 val_mIoU 0.879 val_time 5.797\n",
      "train_loss 0.037 val_loss 0.042 val_acc 0.964 val_mIoU 0.885 val_time 5.596\n",
      "train_loss 0.037 val_loss 0.041 val_acc 0.987 val_mIoU 0.885 val_time 6.008\n",
      "train_loss 0.036 val_loss 0.047 val_acc 0.961 val_mIoU 0.880 val_time 6.040\n",
      "train_loss 0.035 val_loss 0.037 val_acc 0.987 val_mIoU 0.892 val_time 5.867\n",
      "train_loss 0.033 val_loss 0.043 val_acc 0.979 val_mIoU 0.880 val_time 6.071\n",
      "train_loss 0.034 val_loss 0.038 val_acc 0.979 val_mIoU 0.891 val_time 5.648\n",
      "train_loss 0.034 val_loss 0.051 val_acc 0.966 val_mIoU 0.874 val_time 6.196\n",
      "train_loss 0.031 val_loss 0.046 val_acc 0.974 val_mIoU 0.882 val_time 6.235\n",
      "train_loss 0.031 val_loss 0.046 val_acc 0.977 val_mIoU 0.881 val_time 5.911\n",
      "train_loss 0.030 val_loss 0.041 val_acc 0.982 val_mIoU 0.887 val_time 5.975\n",
      "train_loss 0.031 val_loss 0.038 val_acc 0.979 val_mIoU 0.890 val_time 5.834\n",
      "train_loss 0.031 val_loss 0.034 val_acc 0.984 val_mIoU 0.895 val_time 6.629\n",
      "train_loss 0.028 val_loss 0.042 val_acc 0.984 val_mIoU 0.887 val_time 5.954\n",
      "train_loss 0.028 val_loss 0.034 val_acc 0.979 val_mIoU 0.896 val_time 5.829\n",
      "train_loss 0.029 val_loss 0.035 val_acc 0.984 val_mIoU 0.894 val_time 6.177\n",
      "train_loss 0.027 val_loss 0.036 val_acc 0.979 val_mIoU 0.894 val_time 5.735\n",
      "train_loss 0.027 val_loss 0.037 val_acc 0.984 val_mIoU 0.890 val_time 5.814\n",
      "train_loss 0.027 val_loss 0.040 val_acc 0.984 val_mIoU 0.885 val_time 5.842\n",
      "train_loss 0.028 val_loss 0.035 val_acc 0.987 val_mIoU 0.894 val_time 5.699\n",
      "train_loss 0.025 val_loss 0.037 val_acc 0.982 val_mIoU 0.891 val_time 6.225\n",
      "train_loss 0.025 val_loss 0.034 val_acc 0.979 val_mIoU 0.896 val_time 5.851\n",
      "train_loss 0.025 val_loss 0.034 val_acc 0.984 val_mIoU 0.898 val_time 6.089\n",
      "train_loss 0.025 val_loss 0.033 val_acc 0.987 val_mIoU 0.897 val_time 6.509\n",
      "train_loss 0.025 val_loss 0.032 val_acc 0.987 val_mIoU 0.899 val_time 6.571\n",
      "train_loss 0.024 val_loss 0.033 val_acc 0.987 val_mIoU 0.898 val_time 5.684\n",
      "train_loss 0.026 val_loss 0.034 val_acc 0.984 val_mIoU 0.897 val_time 5.907\n",
      "train_loss 0.024 val_loss 0.035 val_acc 0.987 val_mIoU 0.894 val_time 6.128\n",
      "train_loss 0.024 val_loss 0.034 val_acc 0.987 val_mIoU 0.895 val_time 6.092\n",
      "train_loss 0.024 val_loss 0.033 val_acc 0.987 val_mIoU 0.897 val_time 5.733\n",
      "train_loss 0.025 val_loss 0.035 val_acc 0.984 val_mIoU 0.895 val_time 5.705\n",
      "train_loss 0.023 val_loss 0.035 val_acc 0.987 val_mIoU 0.895 val_time 6.169\n",
      "train_loss 0.024 val_loss 0.033 val_acc 0.984 val_mIoU 0.897 val_time 5.678\n",
      "0.02414394882818063\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "lr = 0.0005\n",
    "batch_size = 16\n",
    "train_dl, val_dl = load_split_train_test(datadir, datanames, .1138, batch_size)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                             else \"cpu\")\n",
    "\n",
    "model = Net(3,2)\n",
    "model.to(device);\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4,8,12,16,25,40], gamma=0.6)\n",
    "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.005,step_size_up=9,mode=\"exp_range\",gamma=0.9, cycle_momentum=False,scale_mode =  \"cycle\")\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, lr, epochs=epochs,\n",
    "                                                steps_per_epoch=len(train_dl))\n",
    "model, loss = fit_model(model, optimizer, scheduler, train_dl, val_dl, epochs)\n",
    "print(loss)\n",
    "\n",
    "torch.save(model, 'aerialmodel.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14168.727901,
   "end_time": "2021-04-25T12:54:25.813454",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-25T08:58:17.085553",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
